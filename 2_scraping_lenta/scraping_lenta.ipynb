{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d9165f-a0b9-4890-a69f-daa27d6534f8",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117f16b9-a9a2-4631-9560-26056a05e8c4",
   "metadata": {},
   "source": [
    "We import the necessary libraries and define key parameters for interacting with Lenta’s API: the base URL for fetching categories, the current date for reference, and request headers. The `HEADERS` dictionary contains the minimal set of headers required to receive a valid response from the Lenta API. These headers were determined through testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357155d0-4f45-48b3-86a7-9f4486be3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# define base URLs and headers for making requests throughout the scraping process\n",
    "CATEGORIES_URL = \"https://lenta.com/api-gateway/v1/catalog/categories?timestamp=\"\n",
    "CHECK_DATE = date.today() # current date for reference\n",
    "\n",
    "HEADERS = {\n",
    "    'DeviceID': '42b24bb8-650a-f3a7-fa8d-593e40b478d4',\n",
    "    'Experiments': 'exp_recommendation_cms.true, exp_apigw_purchase.test, exp_lentapay.test, exp_omni_price.test, exp_profile_bell.test, exp_newui_cancel_order.test, exp_newui_history_active_action.test_stars, exp_comment_picker_and_courier.test, exp_general_editing_page.test, exp_cl_omni_support.test, exp_cl_omni_authorization.test, exp_onboarding_sbp.default, exp_fullscreen.test, exp_profile_login.false, exp_new_notifications_show_unauthorized.test, exp_assembly_cost_location.cart, exp_search_bottom.default, exp_onboarding_editing_order.test, exp_cart_new_carousel.default, exp_newui_cart_cancel_editing.test, exp_newui_cart_button.test, exp_new_promov3., exp_sbp_enabled.test, exp_new_my_goods.test, exp_ui_catalog.test, exp_search_out_of_stock.default, exp_profile_settings_email.default, exp_cl_omni_refusalprintreceipts.test, exp_cl_omni_refusalprintcoupons.test, exp_accrual_history.test, exp_personal_recommendations.control, exp_newui_chips.test, exp_loyalty_categories.test, exp_growthbooks_aa.OFF, exp_test_ch_web.def, exp_search_suggestions_popular_sku.default, exp_cancel_subscription.test_2, exp_manage_subscription.control, exp_cl_new_csi.default, exp_cl_new_csat.default, exp_delivery_price_info.default, exp_personal_promo_navigation.test, exp_web_feature_test.true, exp_interval_jump.default, exp_cardOne_promo_type.test, exp_qr_cnc.test, exp_popup_about_order.test, exp_apigw_recommendations.test, exp_where_place_cnc.control, exp_editing_cnc_onboarding.default, exp_editing_cnc.default, exp_selection_carousel.test, exp_pickup_in_delivery.false, exp_feature_kpp_test.false, exp_welcome_onboarding.default, exp_cl_new_splash.default, exp_web_referral_program_type.default, exp_where_place_new.default, exp_start_page.default, exp_promocode_bd_coupon.default, exp_personal_promo_swipe_animation.default, exp_default_payment_type.default, exp_main_page_carousel_vs_banner.default, exp_start_page_onboarding.default, exp_newui_cart_check_edit.default, exp_search_new_logic.default, exp_search_ds_pers_similar.default, exp_growthbooks_aa_id_based_feature.control, exp_referral_program_type.default, exp_my_choice_search.default, exp_items_by_rating.default, exp_can_accept_early.default, exp_test_gb_value.false, exp_online_subscription.default, exp_new_nps_keyboard.test, exp_main_page_carousel_vs_banner_shop.default, exp_bathcing.default, exp_web_qr_cnc.default, exp_hide_cash_payment_for_cnc_wo_adult_items.default, exp_web_promocode_bd_coupon.default, exp_prices_per_quantum.default, exp_test.default123, exp_web_partner_coupons_separately.default, exp_web_chips_online.default',\n",
    "    'SessionToken': 'E05BD3D1115FF4A5D5F0BC02D141EB5A',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',\n",
    "    'X-Delivery-Mode': 'pickup',\n",
    "    'X-Platform': 'omniweb',\n",
    "    'X-Retail-Brand': 'lo',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015df7e-edc1-4c11-ba48-01b7703289bd",
   "metadata": {},
   "source": [
    "### 2. Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6d16b-26ac-4b80-995c-301c22a41cfb",
   "metadata": {},
   "source": [
    "To extract product data from Lenta, we follow a multi-step process: fetch product categories, collect item data by category, clean the results, and save everything in a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11636fcf-0f84-49d4-b41f-a9d1e0021d75",
   "metadata": {},
   "source": [
    "#### 2.1. Fetching Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103bc57-923a-4030-974b-37a0e185c186",
   "metadata": {},
   "source": [
    "We start by retrieving a list of product categories from Lenta’s API. The function extracts relevant fields (*id*, *name*, parent category, *slug* – used to construct URLs and *level*) and returns a cleaned list.\n",
    "\n",
    "The request to the category endpoint requires a dynamic timestamp in milliseconds, which is passed as a query parameter. Each category is identified by a numeric ID and a slug; both are needed for product requests and URL construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe956d8-332a-4772-98b8-deb105f60b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_categories():\n",
    "    \n",
    "    response = requests.get(f'{CATEGORIES_URL}{int(time.time() * 1000)}', headers=HEADERS) # fetch category data from the API endpoint (a timestamp is required in milliseconds)\n",
    "    raw_categories = json.loads(response.text) # convert JSON response to a list of category dictionaries\n",
    "    \n",
    "    cleaned_categories = []\n",
    "    \n",
    "    # go through the raw data and select only the necessary fields\n",
    "    for category in raw_categories[\"categories\"]:    # select the top-level category, save its id and name\n",
    "        cleaned_categories.append({\n",
    "            \"id\": category[\"id\"], # id for further products fetching\n",
    "            \"name\": category[\"name\"], # name for reference\n",
    "            \"parent_id\": category[\"parentId\"] if category[\"parentId\"] != 0 else None, # id and name of a parent category for reference\n",
    "            \"parent_name\": category[\"parentName\"] if category[\"parentName\"] != '' else None, # empty if it's top-level and doesn't have a parent\n",
    "            \"slug\": category[\"slug\"], # category name used in URLs, for further products fetching\n",
    "            \"level\": category[\"level\"] # level of category, to avoid fetching the same categories twice\n",
    "        })\n",
    "\n",
    "    return cleaned_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8203c8-8ca0-4d68-87ca-32b98668c827",
   "metadata": {},
   "source": [
    "We fetch all available categories and save them to a CSV file for transparency and reproducibility. Then, we select only level 2 categories — they strike a balance between breadth and granularity: fewer requests than level 3 (faster and less risk of hitting rate limits), but smaller batches than level 1, which helps minimize data loss if a request fails or we get blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d945e47-de47-4533-8aa7-648c53610ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = fetch_categories()\n",
    "\n",
    "categories_df = pd.DataFrame(categories)\n",
    "categories_df.to_csv(f'categories-{CHECK_DATE}-lenta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bad6f-9cfb-4810-a865-905d41b7b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional intermediate output of the categories list\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "#     display(categories_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619d3a5-595c-481d-8298-06439601407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories_2 = [cat for cat in categories if cat['level'] == 2] # select only level 2 categories\n",
    "# categories_2 = categories_2[:] # this line can be used to resume scraping from a specific point in case of interruption\n",
    "total_categories_count = len(categories_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7bd56-d151-47b4-960a-494bf80725b8",
   "metadata": {},
   "source": [
    "#### 2.2. Fetching Raw Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa7307-51ca-4fba-b825-ebb468b40090",
   "metadata": {},
   "source": [
    "We fetch product listings by mimicking the site’s API, which loads items in paginated batches (up to 40 per request) using an increasing offset. Unlike some other sites, Lenta uses a POST request to return product data (\"items\"), rather than a GET request. The request body includes the category ID, a fixed limit of 40, and an offset that increases by 40 with each page. A few additional fields (filters and sorting) are required but remain constant.\n",
    "\n",
    "Optionally, a `Referer` header pointing to the category’s webpage (constructed using the base URL, slug, and ID) can be included to better mimic browser behavior — although it does not seem to be strictly required.\n",
    "\n",
    "We loop through all pages until all products are retrieved. A random delay between requests reduces the risk of triggering rate limits.\n",
    "\n",
    "The result is raw product data in JSON format, mirroring the structure used on the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553fe2a-603c-42c7-ada8-51431ceb86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_products(category):\n",
    "    \n",
    "    total_products = 1 # initial dummy value to enter the loop\n",
    "    offset = 0\n",
    "    products = []\n",
    "\n",
    "    # set the Referer header to match the category being requested (may help avoid blocking)\n",
    "    # HEADERS['Referer'] = f'https://lenta.com/catalog/{category[\"slug\"]}-{category[\"id\"]}/'\n",
    "    url = 'https://lenta.com/api-gateway/v1/catalog/items'\n",
    "        \n",
    "    while offset < total_products:\n",
    "        \n",
    "        time.sleep(random.uniform(1, 5)) # random time delay to avoid being blocked\n",
    "\n",
    "        # construct request body for POST request\n",
    "        json_data = {\n",
    "            'categoryId': category['id'],\n",
    "            'limit': 40,\n",
    "            'offset': offset,\n",
    "            'sort': {\n",
    "                'type': 'popular',\n",
    "                'order': 'desc',\n",
    "            },\n",
    "            'filters': {\n",
    "                'range': [],\n",
    "                'checkbox': [],\n",
    "                'multicheckbox': [],\n",
    "            },\n",
    "        }\n",
    "    \n",
    "        response = requests.post(url, headers=HEADERS, json=json_data) # fetch product data for the current category, offset, and limit\n",
    "        response_data = json.loads(response.text) # convert into a dictionary\n",
    "        \n",
    "        products += response_data[\"items\"] # extract only products and add them to the list\n",
    "        total_products = response_data[\"total\"] # update total number of products\n",
    "        \n",
    "        offset += 40 # move to the next page of results\n",
    "        \n",
    "        print(f'{len(products)}..', end='') # progress indicator, showing the number of products fetched in the current request\n",
    "\n",
    "    return products    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a3c9e3-b6d8-45ee-9535-7b3de6ca25e5",
   "metadata": {},
   "source": [
    "#### 2.3. Cleaning Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f28a8-a234-48b6-9dce-bb819e8058f9",
   "metadata": {},
   "source": [
    "We define a function to extract only the most relevant fields from the raw data:\n",
    "\n",
    "- Category ID (for traceability)\n",
    "- Product name\n",
    "- Regular price (converted from kopecks to rubles)\n",
    "- Pricing clarification (e.g. net weight)\n",
    "- Supermarket name\n",
    "\n",
    "The result is a cleaned list of product entries, ready for storage or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68de3af-01af-4979-8113-93757e5df6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_product_data(category, raw_products):\n",
    "\n",
    "    cleaned_products = []\n",
    "\n",
    "    # go through the raw data and select only the necessary fields\n",
    "    for product in raw_products:\n",
    "        cleaned_products.append({\n",
    "            \"category_id\": category[\"id\"],\n",
    "            \"name\": product[\"name\"],\n",
    "            \"price\": product[\"prices\"][\"priceRegular\"] / 100, # convert from kopecks to ruble\n",
    "            \"pricing_unit\": product['weight'][\"package\"], # clarifies the unit for the price or the net weight\n",
    "            \"supermarket\": 'Lenta'\n",
    "        })\n",
    "\n",
    "    return cleaned_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45571db-6d84-41c7-abb4-0465b34cfe2c",
   "metadata": {},
   "source": [
    "#### 2.4. Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e53c87-c931-4438-a7af-0f98de9e4959",
   "metadata": {},
   "source": [
    "The following code:\n",
    "\n",
    "1. Iterates through the selected level 2 categories,\n",
    "2. Fetches and cleans product data for each,\n",
    "3. Appends the cleaned data to a single CSV file to build a complete dataset.\n",
    "\n",
    "A progress tracker prints feedback for each category to monitor the scraping process. A short random delay is added between iterations to avoid potential rate-limiting. The output file includes a timestamp (via `CHECK_DATE`) to record when the data was collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625c17e-d516-467a-b13f-42ed9870bfc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fetched_categories_count = 0    # counter for fetching progress tracker\n",
    "\n",
    "# create the file with headers first\n",
    "products_df = pd.DataFrame(columns=[\"category_id\", \"name\", \"price\", \"pricing_unit\", \"supermarket\"])\n",
    "products_df.to_csv(f'scraped_products-{CHECK_DATE}-lenta.csv', index=False, mode='w')\n",
    "\n",
    "for category in categories_2:\n",
    "    \n",
    "    raw_products = fetch_products(category) # fetch products\n",
    "    new_products = clean_product_data(category, raw_products) # select only relevant data and add new products to the list\n",
    "\n",
    "    products_df = pd.DataFrame(new_products)\n",
    "    products_df.to_csv(f'scraped_products-{CHECK_DATE}-lenta.csv', index=False, mode='a', header=False)\n",
    "\n",
    "    fetched_categories_count += 1\n",
    "    print(f'Category ID: {category[\"id\"]} finished, {fetched_categories_count} out of {total_categories_count} categories fetched')\n",
    "    \n",
    "    time.sleep(random.uniform(1, 5))\n",
    "\n",
    "print(f'Fetching complete. Results saved to scraped_products-{CHECK_DATE}-lenta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb51973-71a8-42bc-9ed0-021e36b79bd0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac6f35-e377-4f13-aee1-bd6f6bc05256",
   "metadata": {},
   "source": [
    "### 3. Filtering and Normalizing Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108597e8-b68e-41e6-8826-313e6cbe7e10",
   "metadata": {},
   "source": [
    "After collecting and cleaning the raw product data, we proceed with filtering the dataset to include only the products relevant for comparison. This step involves several stages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d0e1c-d621-4a8a-8c9b-09a86b87b3bc",
   "metadata": {},
   "source": [
    "#### 3.1. Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52572b2-556e-4fbf-a0f8-90d3d51997a5",
   "metadata": {},
   "source": [
    "We start by loading the previously saved product and category datasets and dropping a category_id column that is no longer needed. Also we remove exact duplicates, which may appear if the same item was in more than one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9763d85-3a2d-48d0-9459-da05ce72cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "categories = pd.read_csv('categories-2025-03-04-lenta.csv')\n",
    "products_original = pd.read_csv('scraped_products-2025-03-04-lenta-complete.csv')\n",
    "\n",
    "products = products_original.drop(['category_id'], axis=1)    # drop category_id column\n",
    "products = products.drop_duplicates() # remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec383ebf-e65f-42d3-b543-9a66e07c8007",
   "metadata": {},
   "source": [
    "#### 3.2. Filtering Products by Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3337856-6146-4ffc-bf4e-55fcd100b956",
   "metadata": {},
   "source": [
    "To identify relevant products for comparison, we define a dictionary mapping product types to regular expressions. Each expression captures the base form of the product while deliberately excluding variations (e.g., flavored, processed, or pickled) that fall outside the scope of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a428c-a3ed-4f8e-aa7d-483d24ccdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_regex_map = {\n",
    "    'rice': r'^рис\\b(?!.*овощ)',\n",
    "    'bread': r'(^хлеб\\b|^багет\\b|^батон\\b)(?!.*печеноч)',\n",
    "    'chicken_fillet': r'^филе (кур|груд)(?!.*(копч|соус|запеч|бедр|индей|утен))',\n",
    "    'pork_leg': r'^окорок (свин|из свин)(?!.*(копч|соус))',\n",
    "    'egg': r'^яйцо курин',\n",
    "    'cucumber': r'^огур(цы|ец)(?!.*(солен|маринован|ягод))',\n",
    "    'carrot': r'^морковь(?!.*(корей|отвар))', # matches \"морковь\" and some of its variations, but excludes irrelevant \"морковь по-корейски\" or \"морковь отварная\"\n",
    "    'onion': r'^лук репч(?!.*суш)',\n",
    "    'tomato': r'^томаты(?!.*(сок|очищ|маринован|вялен|солен|измельч|кус))',\n",
    "    'cabbage': r'^капуста\\b.*белокоч',\n",
    "    'eggplant': r'^баклажаны,',\n",
    "    'banana': r'^банан(?!.*(вял|суш|куб))', # matches \"банан\" or \"бананы\", but excludes \"бананы вяленые\" or \"бананы сушеные\"\n",
    "    'orange': r'^апельсин(?!.*(сахар|куб))',\n",
    "    'milk': r'^молоко(?!.*(сгущ|кокос|сух|топл|коз|обогащ|витам|лактоз|печен))',\n",
    "    'yogurt': r'^йогурт\\b(?!.*питье)',\n",
    "    'condensed_milk': r'^молоко.*сгущ(?!.*(варен|кофе|какао))',\n",
    "    'green_tea': r'^чай зел(?!.*порош)',\n",
    "    'black_tea': r'^чай черн',\n",
    "    'ground_coffee': r'^кофе(?!.*(капсул|раствор|фильтр)).*молот',\n",
    "    'sugar': r'^сахар\\b(?!.*(ванил|коричн))',\n",
    "    'salt': r'^соль(?!.*(посуд|ванн|розов|чесн|прян|купан|мельн))',\n",
    "    'sunflower_oil': r'^масло\\b(?!.*(оливк|спрей|аром|вкус|добавл)).*подсолн',\n",
    "    'water': r'^вода\\b(?!.*(малин|клюкв|лимон|цитр)).*негаз',\n",
    "    'buckwheat': r'(^крупа\\b.*гречн|^гречка\\b)(?!.*зел)',\n",
    "    'spaghetti': r'^макароны\\b.*спагетти', # matches \"макароны\" and selects only the \"спагетти\" variety\n",
    "    'rice_noodles': r'(^лапша|^вермишель).*(рис|фунчоз)(?!.*соус)',\n",
    "    'tofu': r'(^продукт)(?!.*(копч|папр)).*тофу|^тофу(?!.*(гриб|томат))',\n",
    "    'mango': r'^манго желт',\n",
    "    'fish_sauce': r'^соус.*рыбн'\n",
    "}\n",
    "product_regex_list = '|'.join(product_regex_map.values()) # create a single regex by joining all individual regexes with the OR operator (|)\n",
    "\n",
    "# filter products matching any of the product types\n",
    "filtered_products = products.loc[products.name.str.contains(product_regex_list, case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb3e4e-a709-48c7-8bb3-8368d7399e30",
   "metadata": {},
   "source": [
    "#### 3.3. Assigning Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7c76d-5d2f-44e0-a1db-fe6f5350cbe9",
   "metadata": {},
   "source": [
    "Each filtered product is tagged with its corresponding product type based on regex matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c442a-3595-4e76-9515-95ee29d09171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_product_type(row):\n",
    "    name = row['name']\n",
    "    for product_type, regex in product_regex_map.items():\n",
    "        match = re.search(regex, name, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            return product_type\n",
    "    return None\n",
    "\n",
    "filtered_products = filtered_products.copy()  # recreate the dataframe\n",
    "filtered_products.loc[:,'product_type'] = filtered_products.apply(assign_product_type, axis=1)\n",
    "\n",
    "# optional intermediate output of the filtered products list\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "#     display(filtered_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fbf97-38fb-473a-b05a-c078cb3f7ef1",
   "metadata": {},
   "source": [
    "#### 3.4. Extracting and Normalizing Units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714926d-9c6f-4953-ad8b-476b1bd16221",
   "metadata": {},
   "source": [
    "Many product listings differ in quantity, weight, or volume. To enable a fair comparison, we extract the relevant information from the product name or pricing clarification field and calculate normalized price metrics such as price per kilogram, per liter, or per unit.\n",
    "\n",
    "- Weight in grams\n",
    "- Number of units (in particular, eggs)\n",
    "- Volume in milliliters\n",
    "\n",
    "Each value is extracted using pattern matching. Not all products contain all values, so some normalization columns (e.g., *price_kg*, *price_lit*, *price_unit*) may be missing depending on the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c617f1a-5d5a-41df-b680-e2bfd427bc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_weight(row):\n",
    "    \"\"\"Extracts total weight in grams from the product name or pricing clarification.\n",
    "    Supports both single weights and multi-portion formats (e.g., '5x100г').\n",
    "    If the product name contains 'весовой', it assumes the weight is 1kg (1000g).\n",
    "    \"\"\"\n",
    "    \n",
    "    name, pricing_unit = row['name'], row['pricing_unit']\n",
    "    pricing_unit = str(pricing_unit) if pd.notna(pricing_unit) else \"\" # handle NaN values as empty\n",
    "    \n",
    "    # multi-portion format (e.g., 5x100г)\n",
    "    match = re.search(r'(\\d+)(x|х)(\\d+|\\d+[,.]\\d+)\\s?г\\b', name) # matches digits х digits g\n",
    "    if match:\n",
    "        portion = float(match.group(1).replace(',', '.')) # extract the number of portions\n",
    "        per_portion = float(match.group(3).replace(',', '.')) # extract the weight per portion\n",
    "        return portion * per_portion # return total weight\n",
    "    # single weight (grams or kilograms)\n",
    "    match = re.search(r'(\\d+|\\d+[,.]\\d+)\\s?(г\\b|кг)', name)\n",
    "    if match:\n",
    "        weight = float(match.group(1).replace(',', '.'))\n",
    "        unit = match.group(2)\n",
    "        return weight * 1000 if unit == 'кг' else weight # convert kilograms to grams\n",
    "    # if name doesn't contain anything, check pricing_unit\n",
    "    match = re.search(r'(\\d+|\\d+[,.]\\d+)\\s?(г\\b|кг)', pricing_unit)\n",
    "    if match:\n",
    "        weight = float(match.group(1).replace(',', '.'))\n",
    "        unit = match.group(2)\n",
    "        return weight * 1000 if unit == 'кг' else weight\n",
    "    # if name contains a word \"весовой\", it means it's a price for 1 kg\n",
    "    match = re.search(r'\\bвесов', name)\n",
    "    if match:\n",
    "        weight = 1000\n",
    "        return weight\n",
    "\n",
    "    return None  # if nothing matched\n",
    "\n",
    "# the next two functions follow the same logic as extract_weight, but for units and milliliters\n",
    "def extract_number_of_units(row):\n",
    "    \"\"\"Extracts number of units from the product name or pricing clarification\n",
    "    ('шт' - piece; 'пак', 'пир', 'саш' - for tea: bag, pyramid, sachet).\n",
    "    \"\"\"\n",
    "    \n",
    "    name, pricing_unit = row['name'], row['pricing_unit']\n",
    "    pricing_unit = str(pricing_unit) if pd.notna(pricing_unit) else \"\"\n",
    "\n",
    "    # check name\n",
    "    match = re.search(r'(\\d+)\\s?(шт|пак|пир|саш)', name)\n",
    "    if match:\n",
    "        number_of_units = int(match.group(1))\n",
    "        return number_of_units\n",
    "    # check pricing_unit\n",
    "    match = re.search(r'(\\d+)\\s?(шт|пак|пир|саш)', pricing_unit)\n",
    "    if match:\n",
    "        number_of_units = int(match.group(1))\n",
    "        return number_of_units\n",
    "\n",
    "    return None  # if nothing matched\n",
    "\n",
    "def extract_volume(row):\n",
    "    \"\"\"Extracts total volume in milliliters from the product name or pricing clarification.\n",
    "    Supports both single and multi-portion formats (e.g., '5x100мл').\n",
    "    \"\"\"\n",
    "    \n",
    "    name, pricing_unit = row['name'], row['pricing_unit']\n",
    "    pricing_unit = str(pricing_unit) if pd.notna(pricing_unit) else \"\"\n",
    "\n",
    "    # multi-portion format (e.g., 5x100мл)\n",
    "    match = re.search(r'(\\d+)(x|х)(\\d+|\\d+[,.]\\d+)\\s?мл', name)\n",
    "    if match:\n",
    "        portion = float(match.group(1).replace(',', '.'))\n",
    "        per_portion = float(match.group(3).replace(',', '.'))\n",
    "        return portion * per_portion\n",
    "    # single volume (liters or milliliters)\n",
    "    match = re.search(r'(\\d+|\\d+[,.]\\d+)\\s?(мл|л\\b)', name)\n",
    "    if match:\n",
    "        volume = float(match.group(1).replace(',', '.'))\n",
    "        unit = match.group(2)\n",
    "        return volume * 1000 if unit == 'л' else volume\n",
    "    # check pricing_unit\n",
    "    match = re.search(r'(\\d+|\\d+[,.]\\d+)\\s?(мл|л\\b)', pricing_unit)\n",
    "    if match:\n",
    "        volume = float(match.group(1).replace(',', '.'))\n",
    "        unit = match.group(2)\n",
    "        return volume * 1000 if unit == 'л' else volume\n",
    "\n",
    "    return None  # if nothing matched\n",
    "\n",
    "filtered_products = filtered_products.copy()  # recreate the dataframe\n",
    "\n",
    "# calculate normalized prices\n",
    "filtered_products.loc[:,'weight'] = filtered_products.apply(extract_weight, axis=1)  # a column with weights in grams\n",
    "filtered_products.loc[:,'price_kg'] = filtered_products.price / filtered_products.weight * 1000   # a column with prices per kg\n",
    "\n",
    "filtered_products.loc[:,'number_of_units'] = filtered_products.apply(extract_number_of_units, axis=1)  # a column with number of units\n",
    "filtered_products.loc[:,'price_unit'] = filtered_products.price / filtered_products.number_of_units   # a column with prices per unit\n",
    "\n",
    "filtered_products.loc[:,'volume'] = filtered_products.apply(extract_volume, axis=1)  # a column with volume in ml\n",
    "filtered_products.loc[:,'price_lit'] = filtered_products.price / filtered_products.volume * 1000   # a column with prices per liter\n",
    "\n",
    "# optional intermediate output\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "#     display(filtered_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa573590-928d-4cbd-87bc-89971f969224",
   "metadata": {},
   "source": [
    "#### 3.5. Saving the Final Filtered Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab9aef-bd2c-4c50-bdfd-b62affca4bb3",
   "metadata": {},
   "source": [
    "Finally, the enriched dataset is saved to a new CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c9246-2f55-49e0-be82-0e2977df56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_products.to_csv(f'filtered_products-2025-03-04-lenta.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
